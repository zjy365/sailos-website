---
title: 'What are the key metrics to monitor for cloud-native applications in a Kubernetes cluster?'
description: 'Cloud-native applications are designed based on containers and microservices and run in Kubernetes clusters. Monitoring their key metrics is crucial to ensuring application availability, performance o'
category: 'Monitoring and Observability'
keywords:
  - 'Cloud-Native'
  - 'Lakehouse'
  - 'High Performance'
  - 'Application Deployment'
  - 'DevOps'
---

Cloud-native applications are designed based on containers and microservices and run in Kubernetes clusters. Monitoring their key metrics is crucial to ensuring application availability, performance optimization, and auto-scaling, which is common in highly dynamic scenarios such as e-commerce or financial services.

Key metrics include resource metrics (e.g., CPU and memory usage), application performance metrics (e.g., request latency, error rate), network metrics (e.g., throughput, number of connections), and Kubernetes-specific metrics (e.g., Pod health status, number of replicas). These facilitate real-time health checks, fault diagnosis, and automatic scaling, improving cluster operation and maintenance efficiency.

The application value of monitoring these metrics lies in enhancing system reliability, optimizing resource costs, and ensuring business continuity; typical scenarios include integrating Prometheus and Grafana for alerting and visual analysis, supporting rapid decision-making and continuous improvement.
